<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Classifiers &#8212; NuPIC 0.7.0.dev0
 documentation</title>
    
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.7.0.dev0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Anomaly Detection" href="anomaly-detection.html" />
    <link rel="prev" title="Temporal Memory" href="temporal-memory.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="classifiers">
<h1>Classifiers<a class="headerlink" href="#classifiers" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-nupic.algorithms.sdr_classifier">
<span id="sdr-classifier"></span><h2>SDR Classifier<a class="headerlink" href="#module-nupic.algorithms.sdr_classifier" title="Permalink to this headline">¶</a></h2>
<p>Implementation of a SDR classifier.</p>
<p>The SDR classifier takes the form of a single layer classification network
that takes SDRs as input and outputs a predicted distribution of classes.</p>
<dl class="class">
<dt id="nupic.algorithms.sdr_classifier.SDRClassifier">
<em class="property">class </em><code class="descclassname">nupic.algorithms.sdr_classifier.</code><code class="descname">SDRClassifier</code><span class="sig-paren">(</span><em>steps=(1</em>, <em>)</em>, <em>alpha=0.001</em>, <em>actValueAlpha=0.3</em>, <em>verbosity=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.sdr_classifier.SDRClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>The SDR Classifier accepts a binary input pattern from the
level below (the &#8220;activationPattern&#8221;) and information from the sensor and
encoders (the &#8220;classification&#8221;) describing the true (target) input.</p>
<p>The SDR classifier maps input patterns to class labels. There are as many
output units as the number of class labels or buckets (in the case of scalar
encoders). The output is a probabilistic distribution over all class labels.</p>
<p>During inference, the output is calculated by first doing a weighted summation
of all the inputs, and then perform a softmax nonlinear function to get
the predicted distribution of class labels</p>
<p>During learning, the connection weights between input units and output units
are adjusted to maximize the likelihood of the model</p>
<p>The SDR Classifier is a variation of the previous CLAClassifier which was
not based on the references below.</p>
<p>Example Usage:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">SDRClassifier</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">actValueAlpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># learning</span>
<span class="n">c</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">recordNum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">patternNZ</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
          <span class="n">classification</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;bucketIdx&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;actValue&quot;</span><span class="p">:</span> <span class="mf">34.7</span><span class="p">},</span>
          <span class="n">learn</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">infer</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># inference</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">recordNum</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">patternNZ</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
                   <span class="n">classification</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;bucketIdx&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;actValue&quot;</span><span class="p">:</span> <span class="mf">34.7</span><span class="p">},</span>
                   <span class="n">learn</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">infer</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Print the top three predictions for 1 steps out.</span>
<span class="n">topPredictions</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;actualValues&quot;</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:</span><span class="mi">3</span><span class="p">]</span>
<span class="k">for</span> <span class="n">probability</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">topPredictions</span><span class="p">:</span>
  <span class="k">print</span> <span class="s2">&quot;Prediction of {} has probability of {}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">,</span>
                                                         <span class="n">probability</span><span class="o">*</span><span class="mf">100.0</span><span class="p">)</span>
</pre></div>
</div>
<p>References:</p>
<ul class="simple">
<li>Alex Graves. Supervised Sequence Labeling with Recurrent Neural Networks,
PhD Thesis, 2008</li>
<li>J. S. Bridle. Probabilistic interpretation of feedforward classification
network outputs, with relationships to statistical pattern recognition</li>
<li>In F. Fogleman-Soulie and J.Herault, editors, Neurocomputing: Algorithms,
Architectures and Applications, pp 227-236, Springer-Verlag, 1990</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>steps</strong> &#8211; (list) Sequence of the different steps of multi-step predictions
to learn</li>
<li><strong>alpha</strong> &#8211; (float) The alpha used to adapt the weight matrix during
learning. A larger alpha results in faster adaptation to the data.</li>
<li><strong>actValueAlpha</strong> &#8211; (float) Used to track the actual value within each
bucket. A lower actValueAlpha results in longer term memory</li>
<li><strong>verbosity</strong> &#8211; (int) verbosity level, can be 0, 1, or 2</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="nupic.algorithms.sdr_classifier.SDRClassifier.compute">
<code class="descname">compute</code><span class="sig-paren">(</span><em>recordNum</em>, <em>patternNZ</em>, <em>classification</em>, <em>learn</em>, <em>infer</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.sdr_classifier.SDRClassifier.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Process one input sample.</p>
<p>This method is called by outer loop code outside the nupic-engine. We
use this instead of the nupic engine compute() because our inputs and
outputs aren&#8217;t fixed size vectors of reals.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>recordNum</strong> &#8211; Record number of this input pattern. Record numbers
normally increase sequentially by 1 each time unless there are missing
records in the dataset. Knowing this information insures that we don&#8217;t get
confused by missing records.</li>
<li><strong>patternNZ</strong> &#8211; List of the active indices from the output below. When the
input is from TemporalMemory, this list should be the indices of the
active cells.</li>
<li><strong>classification</strong> &#8211; <p>Dict of the classification information where:</p>
<ul>
<li>bucketIdx: index of the encoder bucket</li>
<li>actValue: actual value going into the encoder</li>
</ul>
<p>Classification could be None for inference mode.</p>
</li>
<li><strong>learn</strong> &#8211; (bool) if true, learn this sample</li>
<li><strong>infer</strong> &#8211; (bool) if true, perform inference</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><p>Dict containing inference results, there is one entry for each
step in self.steps, where the key is the number of steps, and
the value is an array containing the relative likelihood for
each bucketIdx starting from bucketIdx 0.</p>
<p>There is also an entry containing the average actual value to
use for each bucket. The key is &#8216;actualValues&#8217;.</p>
<p>for example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span><span class="mi">1</span> <span class="p">:</span>             <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
  <span class="mi">4</span> <span class="p">:</span>             <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
  <span class="s1">&#39;actualValues&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="mf">7.6</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.sdr_classifier.SDRClassifier.infer">
<code class="descname">infer</code><span class="sig-paren">(</span><em>patternNZ</em>, <em>classification</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.sdr_classifier.SDRClassifier.infer" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the inference value from one input sample. The actual
learning happens in compute().</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>patternNZ</strong> &#8211; list of the active indices from the output below</li>
<li><strong>classification</strong> &#8211; dict of the classification information:
bucketIdx: index of the encoder bucket
actValue:  actual value going into the encoder</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><p>dict containing inference results, one entry for each step in
self.steps. The key is the number of steps, the value is an
array containing the relative likelihood for each bucketIdx
starting from bucketIdx 0.</p>
<p>for example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;actualValues&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]</span>
  <span class="mi">1</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]</span>
  <span class="mi">4</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]}</span>
</pre></div>
</div>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.sdr_classifier.SDRClassifier.inferSingleStep">
<code class="descname">inferSingleStep</code><span class="sig-paren">(</span><em>patternNZ</em>, <em>weightMatrix</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.sdr_classifier.SDRClassifier.inferSingleStep" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference for a single step. Given an SDR input and a weight
matrix, return a predicted distribution.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>patternNZ</strong> &#8211; list of the active indices from the output below</li>
<li><strong>weightMatrix</strong> &#8211; numpy array of the weight matrix</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">numpy array of the predicted class label distribution</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nupic.algorithms.sdr_classifier_factory.SDRClassifierFactory">
<em class="property">class </em><code class="descclassname">nupic.algorithms.sdr_classifier_factory.</code><code class="descname">SDRClassifierFactory</code><a class="headerlink" href="#nupic.algorithms.sdr_classifier_factory.SDRClassifierFactory" title="Permalink to this definition">¶</a></dt>
<dd><p>Factory for instantiating SDR classifiers.</p>
<dl class="staticmethod">
<dt id="nupic.algorithms.sdr_classifier_factory.SDRClassifierFactory.create">
<em class="property">static </em><code class="descname">create</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.sdr_classifier_factory.SDRClassifierFactory.create" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a SDR classifier factory.
The implementation of the SDR Classifier can be specified with
the &#8220;implementation&#8221; keyword argument.</p>
<dl class="docutils">
<dt>The SDRClassifierFactory uses the implementation as specified in</dt>
<dd><a class="reference external" href="default-config.html">Default NuPIC Configuration</a>.</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="knn-classifier">
<h2>KNN Classifier<a class="headerlink" href="#knn-classifier" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier">
<em class="property">class </em><code class="descclassname">nupic.algorithms.KNNClassifier.</code><code class="descname">KNNClassifier</code><span class="sig-paren">(</span><em>k=1</em>, <em>exact=False</em>, <em>distanceNorm=2.0</em>, <em>distanceMethod='norm'</em>, <em>distThreshold=0</em>, <em>doBinarization=False</em>, <em>binarizationThreshold=0.5</em>, <em>useSparseMemory=True</em>, <em>sparseThreshold=0.1</em>, <em>relativeThreshold=False</em>, <em>numWinners=0</em>, <em>numSVDSamples=None</em>, <em>numSVDDims=None</em>, <em>fractionOfMax=None</em>, <em>verbosity=0</em>, <em>maxStoredPatterns=-1</em>, <em>replaceDuplicates=False</em>, <em>cellsPerCol=0</em>, <em>minSparsity=0.0</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>This class implements NuPIC&#8217;s k Nearest Neighbor Classifier. KNN is very
useful as a basic classifier for many situations. This implementation contains
many enhancements that are useful for HTM experiments. These enhancements
include an optimized C++ class for sparse vectors, support for continuous
online learning, support for various distance methods (including Lp-norm and
raw overlap), support for performing SVD on the input vectors (very useful for
large vectors), support for a fixed-size KNN, and a mechanism to store custom
ID&#8217;s for each vector.</p>
<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.clear">
<code class="descname">clear</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.clear" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears the state of the KNNClassifier.</p>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.closestOtherTrainingPattern">
<code class="descname">closestOtherTrainingPattern</code><span class="sig-paren">(</span><em>inputPattern</em>, <em>cat</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.closestOtherTrainingPattern" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the closest training pattern that is <em>not</em> of the given
category &#8220;cat&#8221;.</p>
<p>&#64;param inputPattern The pattern whose closest neighbor is sought</p>
<dl class="docutils">
<dt>&#64;param cat Training patterns of this category will be ignored no matter</dt>
<dd>their distance to inputPattern</dd>
<dt>&#64;return A dense version of the closest training pattern, or None if no such</dt>
<dd>patterns exist</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.closestTrainingPattern">
<code class="descname">closestTrainingPattern</code><span class="sig-paren">(</span><em>inputPattern</em>, <em>cat</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.closestTrainingPattern" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the closest training pattern to inputPattern that belongs to
category &#8220;cat&#8221;.</p>
<p>&#64;param inputPattern The pattern whose closest neighbor is sought</p>
<p>&#64;param cat The required category of closest neighbor</p>
<dl class="docutils">
<dt>&#64;return A dense version of the closest training pattern, or None if no such</dt>
<dd>patterns exist</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.doIteration">
<code class="descname">doIteration</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.doIteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Utility method to increment the iteration index. Intended for models that
don&#8217;t learn each timestep.</p>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.getClosest">
<code class="descname">getClosest</code><span class="sig-paren">(</span><em>inputPattern</em>, <em>topKCategories=3</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.getClosest" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the index of the pattern that is closest to inputPattern,
the distances of all patterns to inputPattern, and the indices of the k
closest categories.</p>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.getDistances">
<code class="descname">getDistances</code><span class="sig-paren">(</span><em>inputPattern</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.getDistances" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the distances between the input pattern and all other
stored patterns.</p>
<p>&#64;param inputPattern pattern to check distance with</p>
<dl class="docutils">
<dt>&#64;return (distances, categories) numpy arrays of the same length:</dt>
<dd>overlaps: an integer overlap amount for each category
categories: category index for each element of distances</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.getNumPartitionIds">
<code class="descname">getNumPartitionIds</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.getNumPartitionIds" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the number of unique partition Ids stored.</p>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.getOverlaps">
<code class="descname">getOverlaps</code><span class="sig-paren">(</span><em>inputPattern</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.getOverlaps" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the degree of overlap between an input pattern and each category
stored in the classifier. The overlap is computed by compuing:</p>
<blockquote>
<div>logical_and(inputPattern != 0, trainingPattern != 0).sum()</div></blockquote>
<p>&#64;param inputPattern pattern to check overlap of</p>
<dl class="docutils">
<dt>&#64;return (overlaps, categories) Two numpy arrays of the same length:</dt>
<dd>overlaps: an integer overlap amount for each category
categories: category index for each element of overlaps</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.getPartitionId">
<code class="descname">getPartitionId</code><span class="sig-paren">(</span><em>i</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.getPartitionId" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the partition Id associated with pattern i.  Returns None
if no Id is associated with it.</p>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.getPartitionIdList">
<code class="descname">getPartitionIdList</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.getPartitionIdList" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a list containing unique (non-None) partition Ids</p>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.getPartitionIdPerPattern">
<code class="descname">getPartitionIdPerPattern</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.getPartitionIdPerPattern" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a list of numPatterns elements where the i&#8217;th position contains
the integer partition Id associated with pattern i. If pattern i had no
partition Id, it&#8217;s value will be numpy.inf</p>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.getPattern">
<code class="descname">getPattern</code><span class="sig-paren">(</span><em>idx</em>, <em>sparseBinaryForm=False</em>, <em>cat=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.getPattern" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets a training pattern either by index or category number.</p>
<p>&#64;param idx Index of the training pattern</p>
<dl class="docutils">
<dt>&#64;param sparseBinaryForm If true, returns a list of the indices of the</dt>
<dd>non-zero bits in the training pattern</dd>
<dt>&#64;param cat If not None, get the first pattern belonging to category cat. If</dt>
<dd>this is specified, idx must be None.</dd>
</dl>
<p>&#64;return The training pattern with specified index</p>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.getPatternIndicesWithPartitionId">
<code class="descname">getPatternIndicesWithPartitionId</code><span class="sig-paren">(</span><em>partitionId</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.getPatternIndicesWithPartitionId" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a list of pattern indices corresponding to this partitionId.
Return an empty list if there are none</p>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.infer">
<code class="descname">infer</code><span class="sig-paren">(</span><em>inputPattern</em>, <em>computeScores=True</em>, <em>overCategories=True</em>, <em>partitionId=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.infer" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the category that best matches the input pattern. Returns the
winning category index as well as a distribution over all categories.</p>
<p>&#64;param inputPattern (list) A pattern to be classified</p>
<p>&#64;param computeScores NO EFFECT</p>
<p>&#64;param overCategories NO EFFECT</p>
<dl class="docutils">
<dt>&#64;param partitionId (int) If provided, all training vectors with partitionId</dt>
<dd>equal to that of the input pattern are ignored.
For example, this may be used to perform k-fold cross validation
without repopulating the classifier. First partition all the data into
k equal partitions numbered 0, 1, 2, ... and then call learn() for each
vector passing in its partitionId. Then, during inference, by passing
in the partition ID in the call to infer(), all other vectors with the
same partitionId are ignored simulating the effect of repopulating the
classifier while ommitting the training vectors in the same partition.</dd>
<dt>This method returns a 4-tuple: (winner, inferenceResult, dist, categoryDist)</dt>
<dd><dl class="first last docutils">
<dt>winner:           The category with the greatest number of nearest</dt>
<dd>neighbors within the kth nearest neighbors. If the
inferenceResult contains no neighbors, the value of
winner is None. This can happen, for example, in cases
of exact matching, if there are no stored vectors, or if
minSparsity is not met.</dd>
<dt>inferenceResult:  A list of length numCategories, each entry contains the</dt>
<dd>number of neighbors within the top k neighbors that
are in that category.</dd>
<dt>dist:             A list of length numPrototypes. Each entry is the</dt>
<dd>distance from the unknown to that prototype. All
distances are between 0.0 and 1.0</dd>
<dt>categoryDist:     A list of length numCategories. Each entry is the</dt>
<dd>distance from the unknown to the nearest prototype of
that category. All distances are between 0 and 1.0.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.learn">
<code class="descname">learn</code><span class="sig-paren">(</span><em>inputPattern</em>, <em>inputCategory</em>, <em>partitionId=None</em>, <em>isSparse=0</em>, <em>rowID=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the classifier to associate specified input pattern with a
particular category.</p>
<dl class="docutils">
<dt>&#64;param inputPattern (list) The pattern to be assigned a category. If</dt>
<dd>isSparse is 0, this should be a dense array (both ON and OFF bits
present). Otherwise, if isSparse &gt; 0, this should be a list of the
indices of the non-zero bits in sorted order</dd>
<dt>&#64;param inputCategory (int) The category to be associated to the training</dt>
<dd>pattern</dd>
<dt>&#64;param partitionId (int) partitionID allows you to associate an id with each</dt>
<dd>input vector. It can be used to associate input patterns stored in the
classifier with an external id. This can be useful for debugging or
visualizing. Another use case is to ignore vectors with a specific id
during inference (see description of infer() for details). There can be
at most one partitionId per stored pattern (i.e. if two patterns are
within distThreshold, only the first partitionId will be stored). This
is an optional parameter.</dd>
<dt>&#64;param isSparse (int) If 0, the input pattern is a dense representation. If</dt>
<dd>isSparse &gt; 0, the input pattern is a list of non-zero indices and
isSparse is the length of the dense representation</dd>
</dl>
<p>&#64;param rowID (int) UNKNOWN</p>
<p>&#64;return The number of patterns currently stored in the classifier</p>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.remapCategories">
<code class="descname">remapCategories</code><span class="sig-paren">(</span><em>mapping</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.remapCategories" title="Permalink to this definition">¶</a></dt>
<dd><p>Change the category indices.</p>
<p>Used by the Network Builder to keep the category indices in sync with the
ImageSensor categoryInfo when the user renames or removes categories.</p>
<dl class="docutils">
<dt>&#64;param mapping List of new category indices. For example, mapping=[2,0,1]</dt>
<dd>would change all vectors of category 0 to be category 2, category 1 to
0, and category 2 to 1</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nupic.algorithms.KNNClassifier.KNNClassifier.setCategoryOfVectors">
<code class="descname">setCategoryOfVectors</code><span class="sig-paren">(</span><em>vectorIndices</em>, <em>categoryIndices</em><span class="sig-paren">)</span><a class="headerlink" href="#nupic.algorithms.KNNClassifier.KNNClassifier.setCategoryOfVectors" title="Permalink to this definition">¶</a></dt>
<dd><p>Change the category associated with this vector(s).</p>
<p>Used by the Network Builder to move vectors between categories, to enable
categories, and to invalidate vectors by setting the category to -1.</p>
<p>&#64;param vectorIndices Single index or list of indices</p>
<dl class="docutils">
<dt>&#64;param categoryIndices Single index or list of indices. Can also be a</dt>
<dd>single index when vectorIndices is a list, in which case the same
category will be used for all vectors</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/numenta-logo.png" alt="Logo"/>
            </a></p>
<h1 class="logo"><a href="../../index.html">NuPIC</a></h1>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=numenta&repo=nupic&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../quick-start/index.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides/index.html">Guides</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">API Docs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../opf/index.html">Online Prediction Framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../network/index.html">Network API</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Algorithms</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="encoders.html">Encoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="encoders.html#data">Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="spatial-pooler.html">Spatial Pooler</a></li>
<li class="toctree-l3"><a class="reference internal" href="temporal-memory.html">Temporal Memory</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Classifiers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-nupic.algorithms.sdr_classifier">SDR Classifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="#knn-classifier">KNN Classifier</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="anomaly-detection.html">Anomaly Detection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../io.html">Input / Output</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing/index.html">Contributing</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Numenta.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="../../_sources/api/algorithms/classifiers.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/numenta/nupic" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>